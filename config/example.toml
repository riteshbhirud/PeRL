[model]
    model_name_or_path = "Qwen/Qwen3-0.6B"

[peft]
    use_peft = true
    task_type = "CAUSAL_LM"
    use_dora = true
    r = 8
    lora_alpha = 32
    lora_dropout = 0.1
    target_modules = ["q_proj", "v_proj"]

[training]
    dtype = "bfloat16"
    lr = 1e-6
    output_dir = ""
    run_name = "grpo-lora-qwen3-0.6b"
    remove_unused_columns = false
    gradient_accumulation_steps = 16
    num_train_epochs = 1
    bf16 = true
    max_completion_length = 64
    num_generations = 4
    max_prompt_length = 128
    logging_steps = 10
    save_strategy = "steps"
    save_steps = 10
    use_vllm = false # do not use vllm and rollout w/ model.generate instead

[dataset]
    dataset_name_or_path = "AI-MO/NuminaMath-TIR"